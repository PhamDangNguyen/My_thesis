{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzO4YcGo0-aH",
        "outputId": "9119e216-e2cd-44d3-c24e-93dab8958ed9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'yolov7'...\n",
            "remote: Enumerating objects: 1197, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 1197 (delta 2), reused 3 (delta 1), pack-reused 1191\u001b[K\n",
            "Receiving objects: 100% (1197/1197), 74.23 MiB | 28.33 MiB/s, done.\n",
            "Resolving deltas: 100% (517/517), done.\n"
          ]
        }
      ],
      "source": [
        "!# Download YOLOv7 code\n",
        "!git clone https://github.com/WongKinYiu/yolov7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PYeXiF8ml6v",
        "outputId": "70de4343-b60d-4473-9615-1386cd877c54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/1.zip\n",
            "  inflating: /content/1.mp4          \n"
          ]
        }
      ],
      "source": [
        "!unzip \"/content/1.zip\" -d \"/content\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSXDKEXkmvbl",
        "outputId": "2c3b74c7-1b7e-4a36-971f-87d74424420d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31m\u001b[1mrequirements:\u001b[0m jedi>=0.16 not found and is required by YOLOR, attempting auto-update...\n",
            "Collecting jedi>=0.16\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 13.3 MB/s eta 0:00:00\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16) (0.8.3)\n",
            "Installing collected packages: jedi\n",
            "Successfully installed jedi-0.19.1\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m 1 package updated per /content/yolov7/requirements.txt\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "Adding autoShape... \n",
            "Adding autoShape... \n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "path_model = '/content/drive/MyDrive/bestv7.pt'\n",
        "path_model2 = '/content/drive/MyDrive/exp_Dropletv7/weights/best.pt'\n",
        "model = torch.hub.load('/content/yolov7', 'custom', path_model ,force_reload=True, source='local',trust_repo=True)\n",
        "model_Droplet = torch.hub.load('/content/yolov7', 'custom', path_model2,force_reload=True, source='local',trust_repo=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JNRD7F1qmgz2"
      },
      "outputs": [],
      "source": [
        "# class 0 is cell, 1 is droplet\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def invest_pp(img,para):\n",
        "  use = img #.astype(np.float32)\n",
        "  use = cv2.cvtColor(use,cv2.COLOR_RGB2BGR)\n",
        "  use = cv2.resize(use,para,interpolation=cv2.INTER_CUBIC)\n",
        "  return use\n",
        "\n",
        "def predict(img,model,threshold = 0.5,param=(0,0)):\n",
        "  detections = model(img)\n",
        "  check_img = img.copy()\n",
        "  count = 0\n",
        "  results = detections.pandas().xyxy[0].to_dict(orient=\"records\")\n",
        "  #filter\n",
        "  for result in results:\n",
        "    conf = result['confidence']\n",
        "    name = result['name']\n",
        "    class_ = result['class']\n",
        "    if name =='Plastic microbeads' and conf > 0.5:\n",
        "      count+=1\n",
        "  return count\n",
        "def find_cnts(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    gray = cv2.GaussianBlur(gray,(11,11),0)\n",
        "    canny_cv = cv2.Canny(gray,650,1150,apertureSize=5,L2gradient= True)\n",
        "    canny_cv = cv2.dilate(canny_cv, None, iterations=4)\n",
        "    canny_cv = cv2.erode(canny_cv, None, iterations=3)\n",
        "    cnts, hierarchy = cv2.findContours(canny_cv, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    return cnts\n",
        "    # return gray,canny_cv,cnts\n",
        "def pp(img,sizee = (640,640)):\n",
        "  use = img #.astype(np.float32)\n",
        "  use = cv2.cvtColor(use,cv2.COLOR_BGR2RGB)\n",
        "  use = cv2.resize(use,sizee,interpolation=cv2.INTER_CUBIC)\n",
        "  # use = cv2.resize(use,sizee)\n",
        "  return use\n",
        "def vote(arr):\n",
        "  arr = np.array(arr)\n",
        "  counts = np.bincount(arr)\n",
        "  # print(counts)\n",
        "  # print(np.argmax(counts))\n",
        "  return np.argmax(counts)\n",
        "\n",
        "def get_info_Droplets(img,threshold = 0.5):\n",
        "  use_img = pp(img)\n",
        "  detections = model_Droplet(use_img)\n",
        "  results = detections.pandas().xyxy[0].to_dict(orient=\"records\")\n",
        "  Arr_tensor = []\n",
        "  for result in results:\n",
        "    conf = result['confidence']\n",
        "    name = result['name']\n",
        "    class_ = result['class']\n",
        "    if name =='ADroplet' and conf > 0.5:\n",
        "      tensor = (int(result['xmin']),int(result['ymin']),int(result['xmax']),int(result['ymax']))\n",
        "      cv2.rectangle(use_img,(int(result['xmin']),int(result['ymin'])),(int(result['xmax']),int(result['ymax'])),(12,158,200),2)\n",
        "      Arr_tensor.append(tensor)\n",
        "  return Arr_tensor, len(Arr_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4wZYhIa0--1",
        "outputId": "ec4f5c9d-2eee-47a0-ced4-b4aa608356b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[7, 6, 5, 5, 5, 5, 5, 5]\n",
            "1\n",
            "[5, 5, 2, 2, 2, 2, 2, 2]\n",
            "2\n",
            "[8, 8, 9, 9, 9, 9, 8, 8]\n",
            "3\n",
            "[2, 0, 0, 2, 0, 0, 0, 0]\n",
            "4\n",
            "[3, 3, 3, 4, 4, 3, 3, 3]\n",
            "5\n",
            "[2, 1, 1, 1, 1, 1, 1, 1]\n",
            "6\n",
            "[3, 3, 3, 2, 2, 2, 3, 3]\n",
            "7\n",
            "[0, 0, 0, 0, 0, 0, 0, 0]\n",
            "8\n",
            "[4, 4, 4, 2, 2, 2, 2, 2]\n",
            "9\n",
            "[2, 2, 1, 1, 1, 2, 1, 1]\n",
            "10\n",
            "[2, 1, 1, 1, 1, 1, 1, 1]\n",
            "11\n",
            "[3, 2, 2, 2, 2, 3, 2, 2]\n",
            "12\n",
            "[2, 2, 2, 2, 2, 2, 2, 2]\n",
            "13\n",
            "[2, 1, 1, 1, 1, 1, 1, 1]\n",
            "14\n",
            "[1, 1, 1, 0, 0, 1, 0, 0]\n",
            "15\n",
            "[0, 0, 0, 0, 0, 1, 0, 0]\n",
            "16\n",
            "[2, 1, 1, 1, 2, 2, 1, 1]\n",
            "17\n",
            "[1, 1, 0, 0, 0, 0, 0, 1]\n",
            "18\n",
            "[1, 1, 1, 1, 2, 2, 1, 1]\n",
            "19\n",
            "[2, 2, 0, 1, 1, 1, 1, 1]\n",
            "20\n",
            "[0, 0, 1, 1, 1, 1, 1, 1]\n",
            "21\n",
            "[1, 1, 0, 1, 1, 2, 1, 1]\n",
            "22\n",
            "[1, 1, 0, 0, 0, 0, 0, 0]\n",
            "23\n",
            "[1, 1, 1, 0, 0, 0, 0, 0]\n",
            "24\n",
            "[2, 2, 2, 2, 2, 2, 2, 2]\n",
            "25\n",
            "[1, 1, 1, 1, 1, 1, 1, 1]\n",
            "26\n",
            "[1, 1, 1, 1, 1, 1, 1, 1]\n",
            "27\n",
            "[0, 0, 0, 0, 0, 0, 0, 0]\n",
            "28\n",
            "[1, 1, 1, 1, 1, 2, 2, 1]\n",
            "29\n",
            "[0, 0, 0, 0, 0, 0, 0, 0]\n",
            "30\n",
            "[1, 0, 0, 0, 0, 0, 0, 0]\n",
            "31\n",
            "[1, 1, 1, 0, 0, 0, 0, 0]\n",
            "32\n",
            "[1, 1, 1, 1, 1, 1, 1, 1]\n",
            "33\n",
            "[1, 1, 0, 1, 1, 0, 0, 1]\n",
            "34\n",
            "[0, 0, 0, 0, 0, 0, 0, 0]\n",
            "35\n",
            "[0, 0, 0, 1, 0, 0, 0, 0]\n",
            "36\n",
            "[0, 0, 0, 0, 0, 0, 0, 0]\n",
            "37\n",
            "[0, 0, 0, 0, 0, 0, 0, 0]\n",
            "38\n",
            "[0, 0, 0, 0, 0, 0, 1, 1]\n",
            "39\n",
            "[0, 0, 0, 0, 0, 0, 1, 1]\n",
            "40\n",
            "[0, 0, 0, 0, 0, 0, 1, 1]\n",
            "41\n",
            "[1, 1, 1, 1, 2, 2, 2, 1]\n",
            "42\n",
            "[0, 1, 1, 0, 1, 1, 1, 0]\n",
            "43\n",
            "[1, 0, 0, 0, 0, 0, 0, 0]\n",
            "44\n",
            "[0, 2, 2, 0, 0, 0, 1, 0]\n",
            "45\n",
            "[0, 1, 1, 0, 0, 0, 0, 0]\n",
            "46\n",
            "[1, 1, 0, 0, 0, 0, 0, 0]\n",
            "47\n",
            "[1, 1, 0, 0, 0, 0, 0, 0]\n",
            "48\n",
            "[0, 0, 0, 0, 0, 0, 1, 1]\n",
            "49\n",
            "[0, 1, 1, 0, 0, 0, 0, 0]\n",
            "50\n",
            "[0, 0, 0, 0, 0, 0, 1, 0]\n",
            "51\n",
            "[0, 0, 0, 0, 0, 0, 1, 1]\n",
            "52\n",
            "[0, 0, 0, 1, 1, 1, 0, 0]\n",
            "53\n",
            "[0, 0, 0, 0, 0, 0, 1, 1]\n",
            "54\n",
            "[0, 0, 4, 4, 4, 4, 6, 6]\n",
            "55\n",
            "[1, 1, 2, 1, 1, 3, 8, 8]\n",
            "56\n",
            "[5, 5, 5, 5, 4, 6, 5, 5]\n",
            "57\n",
            "[2, 2, 2, 3, 3, 3, 3, 4]\n",
            "58\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from sklearn import metrics\n",
        "import pandas as pd\n",
        "import os\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "top_left_box = [248,200]#200\n",
        "bottom_right_box = [385,500]#400\n",
        "\n",
        "id = 0\n",
        "video_path = '/content/1.mp4'\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "cl = [(0,0,0),(0,255,0),(0,0,255)] #black, green, red\n",
        "color_ = cl[2]\n",
        "Arr_count = []\n",
        "Sign_frameOrigin = True\n",
        "\n",
        "frame_width = 640\n",
        "frame_height = 640\n",
        "frame_rate = 30\n",
        "\n",
        "count_frame = 0\n",
        "\n",
        "# Tạo đối tượng VideoWriter để lưu video\n",
        "video_output_filename = '8_frame.avi'\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "out = cv2.VideoWriter(video_output_filename, fourcc, frame_rate, (frame_width, frame_height))\n",
        "\n",
        "\n",
        "numberCells = None\n",
        "\n",
        "\n",
        "if (cap.isOpened()== False):\n",
        "    print(\"Error opening video file\")\n",
        "while cap.isOpened():\n",
        "    ret, img = cap.read()\n",
        "    if ret: # có ảnh là show\n",
        "      frame_sub = img[250:900,525:1265]\n",
        "      frame_sub = cv2.resize(frame_sub, (640, 640))\n",
        "      img_sub = frame_sub.copy()#don't draw in here\n",
        "\n",
        "      cv2.putText(frame_sub, f'{numberCells}',(300,180),cv2.FONT_HERSHEY_SIMPLEX,1,(255, 0, 0),2, cv2.LINE_AA)\n",
        "\n",
        "      cv2.rectangle(frame_sub, (top_left_box[0],top_left_box[1]),(bottom_right_box[0],bottom_right_box[1]), color_, 2)\n",
        "      Arr_in4,len_Arrin4 = get_info_Droplets(img_sub)\n",
        "\n",
        "      check = 0\n",
        "\n",
        "      for i in range(0,len_Arrin4):\n",
        "        x1,y1,x2,y2 = Arr_in4[i][0],Arr_in4[i][1],Arr_in4[i][2],Arr_in4[i][3]\n",
        "        # print(Arr_in4[i])\n",
        "        # print(\"And\")\n",
        "        if (y1 > top_left_box[1] and y2 < bottom_right_box[1]):\n",
        "          cv2.rectangle(frame_sub, (x1,y1),(x2,y2), cl[1], 2)\n",
        "          c_x = (x1+x2)/2\n",
        "          c_y = (y1+y2)/2\n",
        "          h_ = y2-y1\n",
        "          x1_new = int(c_x - h_/2)\n",
        "          x2_new = int(c_x + h_/2)\n",
        "          y1_new = int(c_y - h_/2)\n",
        "          y2_new = int(c_y + h_/2)\n",
        "          use_predImg = img_sub[y1_new:y2_new,x1_new:x2_new]\n",
        "          used_pred = pp(use_predImg)\n",
        "          count = predict(used_pred,model,param=(x2_new-x1_new,y2_new-y1_new))\n",
        "          # print(count)\n",
        "          Arr_count.append(count)\n",
        "          # cv2_imshow(use_predImg)\n",
        "          check = 1\n",
        "\n",
        "      # cv2_imshow(img)\n",
        "      # print(len_Arrin4)\n",
        "\n",
        "      if(check == 0 and Arr_count != []): # trong 1 frame khong co giot nao trong vung lam viec\n",
        "        Arr_count_7 = Arr_count[0:8]\n",
        "        numberCells = vote(Arr_count_7)\n",
        "        if len(Arr_count_7)>=8:\n",
        "          print(Arr_count_7)\n",
        "          Arr_count = []\n",
        "          id = id + 1\n",
        "          print(id)\n",
        "\n",
        "      out.write(frame_sub)\n",
        "      if cv2.waitKey(25) & 0xFF == ord('q'):\n",
        "        break\n",
        "    else:\n",
        "        break\n",
        "cap.release()\n",
        "out.release()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}