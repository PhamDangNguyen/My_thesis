{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWG0xP87soPN",
        "outputId": "46254ca5-2b70-44e9-88d6-c43faa4ad2df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2d_dxJruVl1",
        "outputId": "64fd0324-51cb-4d83-e9cb-8030fde976fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/Real_Filter.zip\n",
            "  inflating: /content/Real_Filter.mp4  \n"
          ]
        }
      ],
      "source": [
        "!unzip \"/content/Real_Filter.zip\" -d \"/content\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qugUqn4Ouwe2",
        "outputId": "3e1dac62-67da-4d85-dd1c-9938d930b570"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/hub.py:294: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
            "  warnings.warn(\n",
            "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['gitpython>=3.1.30', 'Pillow>=10.0.1'] not found, attempting AutoUpdate...\n",
            "Collecting gitpython>=3.1.30\n",
            "  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 190.6/190.6 kB 5.6 MB/s eta 0:00:00\n",
            "Collecting Pillow>=10.0.1\n",
            "  Downloading Pillow-10.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.6 MB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3.6/3.6 MB 92.0 MB/s eta 0:00:00\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython>=3.1.30)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 62.7/62.7 kB 234.7 MB/s eta 0:00:00\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython>=3.1.30)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, Pillow, gitdb, gitpython\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "Successfully installed Pillow-10.1.0 gitdb-4.0.11 gitpython-3.1.40 smmap-5.0.1\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success âœ… 6.0s, installed 2 packages: ['gitpython>=3.1.30', 'Pillow>=10.0.1']\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m âš ï¸ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-11-13 Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7015519 parameters, 0 gradients, 15.8 GFLOPs\n",
            "Adding AutoShape... \n",
            "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
            "YOLOv5 ğŸš€ 2023-11-13 Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "model = torch.hub.load('ultralytics/yolov5', 'custom',path='/content/drive/MyDrive/Machine_Learning/YOLO/yolov5/Object_detection/Vi_nhua/Full/weights/best.pt', force_reload=True)\n",
        "model_Droplet = torch.hub.load('ultralytics/yolov5', 'custom',path='/content/drive/MyDrive/Machine_Learning/YOLO/yolov5/Object_detection/Vi_nhua/Droplet_thuan/weights/best.pt', force_reload=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pfpl2X7QuqKs"
      },
      "outputs": [],
      "source": [
        "# class 0 is cell, 1 is droplet\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def invest_pp(img,para):\n",
        "  use = img #.astype(np.float32)\n",
        "  use = cv2.cvtColor(use,cv2.COLOR_RGB2BGR)\n",
        "  use = cv2.resize(use,para,interpolation=cv2.INTER_CUBIC)\n",
        "  return use\n",
        "\n",
        "def predict(img,model,threshold = 0.5,param=(0,0)):\n",
        "  detections = model(img)\n",
        "  check_img = img.copy()\n",
        "  count = 0\n",
        "  results = detections.pandas().xyxy[0].to_dict(orient=\"records\")\n",
        "  #filter\n",
        "  for result in results:\n",
        "    conf = result['confidence']\n",
        "    name = result['name']\n",
        "    class_ = result['class']\n",
        "    if name =='Plastic microbeads' and conf > 0.5:\n",
        "      count+=1\n",
        "      cv2.rectangle(check_img,(int(result['xmin']),int(result['ymin'])),(int(result['xmax']),int(result['ymax'])),(12,158,200),2)\n",
        "  check_img = invest_pp(check_img,param)\n",
        "  return count,check_img\n",
        "def find_cnts(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    gray = cv2.GaussianBlur(gray,(11,11),0)\n",
        "    canny_cv = cv2.Canny(gray,650,1150,apertureSize=5,L2gradient= True)\n",
        "    canny_cv = cv2.dilate(canny_cv, None, iterations=4)\n",
        "    canny_cv = cv2.erode(canny_cv, None, iterations=3)\n",
        "    cnts, hierarchy = cv2.findContours(canny_cv, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    return cnts\n",
        "    # return gray,canny_cv,cnts\n",
        "def pp(img,sizee = (640,640)):\n",
        "  use = img #.astype(np.float32)\n",
        "  use = cv2.cvtColor(use,cv2.COLOR_BGR2RGB)\n",
        "  use = cv2.resize(use,sizee,interpolation=cv2.INTER_CUBIC)\n",
        "  # use = cv2.resize(use,sizee)\n",
        "  return use\n",
        "def vote(arr):\n",
        "  arr = np.array(arr)\n",
        "  counts = np.bincount(arr)\n",
        "  # print(counts)\n",
        "  # print(np.argmax(counts))\n",
        "  return np.argmax(counts)\n",
        "\n",
        "def get_info_Droplets(img,threshold = 0.5):\n",
        "  use_img = pp(img)\n",
        "  detections = model_Droplet(use_img)\n",
        "  results = detections.pandas().xyxy[0].to_dict(orient=\"records\")\n",
        "  Arr_tensor = []\n",
        "  for result in results:\n",
        "    conf = result['confidence']\n",
        "    name = result['name']\n",
        "    class_ = result['class']\n",
        "    if name =='ADroplet' and conf > 0.5:\n",
        "      tensor = (int(result['xmin']),int(result['ymin']),int(result['xmax']),int(result['ymax']))\n",
        "      cv2.rectangle(use_img,(int(result['xmin']),int(result['ymin'])),(int(result['xmax']),int(result['ymax'])),(12,158,200),2)\n",
        "      Arr_tensor.append(tensor)\n",
        "    img_new = invest_pp(use_img,(650,740))\n",
        "  return Arr_tensor, len(Arr_tensor)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Qtf5XbnY5XO"
      },
      "source": [
        "# **DÃ¹ng Xá»­ lÃ½ áº£nh Detect Droplets**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz6TYh3WtEEA"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from sklearn import metrics\n",
        "import pandas as pd\n",
        "import os\n",
        "from google.colab.patches import cv2_imshow\n",
        "top_left_box = [50,200]#200\n",
        "bottom_right_box = [138,500]#400\n",
        "id = 0\n",
        "video_path = '/content/1.mp4'\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "cl = [(0,0,0),(0,255,0),(0,0,255)] #black, green, red\n",
        "color_ = cl[2]\n",
        "Arr_count = []\n",
        "Sign_frameOrigin = True\n",
        "\n",
        "frame_width = 180\n",
        "frame_height = 700\n",
        "frame_rate = 30\n",
        "\n",
        "\n",
        "count_frame = 0\n",
        "\n",
        "\n",
        "# Táº¡o Ä‘á»‘i tÆ°á»£ng VideoWriter Ä‘á»ƒ lÆ°u video\n",
        "video_output_filename = '3_frame.avi'\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "out = cv2.VideoWriter(video_output_filename, fourcc, frame_rate, (frame_width, frame_height))\n",
        "\n",
        "if (cap.isOpened()== False):\n",
        "    print(\"Error opening video file\")\n",
        "while cap.isOpened():\n",
        "    ret, img = cap.read()\n",
        "    if ret: # cÃ³ áº£nh lÃ  show\n",
        "      frame_sub = img[200:900,800:980]#N_them\n",
        "      cnts = find_cnts(frame_sub)\n",
        "      # cv2.drawContours(frame_sub, cnts, -1, (0, 255, 0), 2)\n",
        "      cv2.rectangle(frame_sub, (top_left_box[0],top_left_box[1]),(bottom_right_box[0],bottom_right_box[1]), color_, 2)\n",
        "      if len(cnts) > 0:\n",
        "        check = 0\n",
        "        for i in range (0,len(cnts)-1):\n",
        "          x_, y_, w_, h_ = cv2.boundingRect(cnts[i])\n",
        "          if (y_ > top_left_box[1] and y_+h_ < bottom_right_box[1] and w_ > 10 and h_ > 10):\n",
        "            cv2.rectangle(frame_sub, (x_,y_),(x_+w_,y_+h_), cl[1], 2)\n",
        "            c_x = x_  + w_/2\n",
        "            c_y = y_ + h_/2\n",
        "            if (x_ > y_):\n",
        "              x_new_1 = int(c_x - w_/2)\n",
        "              y_new_1 = int(c_y - w_/2)\n",
        "              x_new_2 = int(c_x + w_/2)\n",
        "              y_new_2 = int(c_y + w_/2)\n",
        "            else:\n",
        "              x_new_1 = int(c_x - h_/2)\n",
        "              y_new_1 = int(c_y - h_/2)\n",
        "              x_new_2 = int(c_x + h_/2)\n",
        "              y_new_2 = int(c_y + h_/2)\n",
        "\n",
        "            # sub_img = frame_sub[y_:y_+h_,x_:x_+w_]\n",
        "            sub_img = frame_sub[y_new_1:y_new_2,x_new_1:x_new_2]\n",
        "            use_predImg = pp(sub_img)\n",
        "            count,check_img = predict(use_predImg,model,param=(x_new_2-x_new_1,y_new_2-y_new_1))\n",
        "            # print(count)\n",
        "            # cv2_imshow(frame_sub)\n",
        "            Arr_count.append(count)\n",
        "            # cv2_imshow(frame_sub)\n",
        "            # frame_sub[y_new_1:y_new_2,x_new_1:x_new_2] = check_img\n",
        "            check = 1\n",
        "\n",
        "        # print(check)\n",
        "        if(check == 0 and Arr_count != []):\n",
        "          Arr_count_8 = Arr_count[0:8]\n",
        "          numberCells = vote(Arr_count_8)\n",
        "          if len(Arr_count_8)>=8:\n",
        "            cv2.putText(frame_sub, f'{numberCells}',(50,180),cv2.FONT_HERSHEY_SIMPLEX,1,(255, 0, 0),2, cv2.LINE_AA)\n",
        "            print(Arr_count_8)\n",
        "          Arr_count = []\n",
        "          Sign_frameOrigin = True\n",
        "      out.write(frame_sub)\n",
        "      if cv2.waitKey(25) & 0xFF == ord('q'):\n",
        "        break\n",
        "    else:\n",
        "        break\n",
        "cap.release()\n",
        "out.release()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SU_55d2EY_rI"
      },
      "source": [
        "# **DÃ¹ng Model detect droplets**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1LMq101ZGJf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c66e5d64-45fb-4377-8ee4-09445251adf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5, 5, 5, 5, 5, 5, 6, 6]\n",
            "1\n",
            "[3, 2, 2, 2, 2, 2, 2, 4]\n",
            "2\n",
            "[7, 7, 4, 8, 8, 8, 8, 7]\n",
            "3\n",
            "[0, 0, 0, 2, 2, 0, 0, 0]\n",
            "4\n",
            "[3, 3, 3, 4, 4, 4, 3, 3]\n",
            "5\n",
            "[1, 1, 1, 2, 2, 2, 1, 1]\n",
            "6\n",
            "[4, 4, 4, 5, 5, 4, 3, 3]\n",
            "7\n",
            "[0, 0, 0, 1, 0, 0, 0, 1]\n",
            "8\n",
            "[4, 4, 4, 3, 3, 4, 4, 4]\n",
            "9\n",
            "[1, 2, 2, 1, 1, 2, 2, 2]\n",
            "10\n",
            "[1, 1, 1, 1, 2, 1, 1, 2]\n",
            "11\n",
            "[2, 1, 1, 2, 2, 2, 3, 2]\n",
            "12\n",
            "[2, 2, 3, 2, 3, 3, 2, 4]\n",
            "13\n",
            "[2, 1, 1, 1, 1, 1, 2, 1]\n",
            "14\n",
            "[0, 1, 1, 0, 2, 1, 1, 0]\n",
            "15\n",
            "[1, 0, 0, 0, 1, 0, 0, 1]\n",
            "16\n",
            "[1, 1, 1, 2, 2, 2, 3, 2]\n",
            "17\n",
            "[0, 1, 0, 0, 1, 2, 1, 0]\n",
            "18\n",
            "[2, 2, 2, 2, 1, 2, 2, 1]\n",
            "19\n",
            "[2, 2, 2, 1, 2, 2, 2, 2]\n",
            "20\n",
            "[1, 1, 2, 1, 1, 0, 0, 1]\n",
            "21\n",
            "[2, 0, 0, 1, 1, 1, 0, 0]\n",
            "22\n",
            "[1, 1, 1, 1, 1, 0, 0, 0]\n",
            "23\n",
            "[2, 2, 2, 2, 1, 1, 1, 1]\n",
            "24\n",
            "[2, 2, 2, 2, 2, 2, 2, 2]\n",
            "25\n",
            "[2, 2, 1, 1, 1, 2, 1, 1]\n",
            "26\n",
            "[2, 2, 1, 1, 1, 1, 2, 2]\n",
            "27\n",
            "[0, 0, 0, 0, 0, 0, 1, 1]\n",
            "28\n",
            "[1, 1, 1, 1, 1, 1]\n",
            "29\n",
            "[0, 0, 0, 0, 1]\n",
            "30\n",
            "[0, 0, 0, 0, 0, 0, 0]\n",
            "31\n",
            "[0, 0, 0, 1, 0, 0]\n",
            "32\n",
            "[1, 1, 1, 1, 1, 1]\n",
            "33\n",
            "[1, 2, 1, 3, 3, 1]\n",
            "34\n",
            "[2, 1, 1, 1, 1, 1]\n",
            "35\n",
            "[0, 0, 0, 0, 0, 0]\n",
            "36\n",
            "[0, 0, 0, 0, 0, 0, 0]\n",
            "37\n",
            "[0, 0, 0, 0, 0, 0]\n",
            "38\n",
            "[0, 0, 1, 1, 0, 1]\n",
            "39\n",
            "[0, 0, 0, 0, 0, 0]\n",
            "40\n",
            "[0, 0, 0, 0, 0]\n",
            "41\n",
            "[0, 0, 1, 0, 0, 0, 0]\n",
            "42\n",
            "[0, 0, 0, 0, 0, 0]\n",
            "43\n",
            "[0, 1, 1, 0, 1]\n",
            "44\n",
            "[1, 1, 1, 1, 0]\n",
            "45\n",
            "[1, 1, 1, 1, 1]\n",
            "46\n",
            "[1, 1, 1, 0]\n",
            "47\n",
            "[0, 0, 0, 0, 1, 1]\n",
            "48\n",
            "[1, 1, 1, 0, 0]\n",
            "49\n",
            "[1, 1, 1, 0, 0]\n",
            "50\n",
            "[1, 1, 0, 2, 2]\n",
            "51\n",
            "[1, 1, 1, 0, 0, 0]\n",
            "52\n",
            "[1, 1, 1, 0, 1, 1]\n",
            "53\n",
            "[0, 0, 0, 0, 0, 1]\n",
            "54\n",
            "[1, 1, 1, 1]\n",
            "55\n",
            "[1, 1, 1, 0, 0, 0]\n",
            "56\n",
            "[0, 0, 0, 0, 0, 0]\n",
            "57\n",
            "[1, 1, 1, 0, 1, 1]\n",
            "58\n",
            "[0, 1, 1, 0, 0, 0]\n",
            "59\n",
            "[0, 0, 0, 0, 0, 0]\n",
            "60\n",
            "[1, 1, 1, 1, 1, 0]\n",
            "61\n",
            "[0, 0, 0, 0, 1, 0]\n",
            "62\n",
            "[0, 0, 0, 1, 0]\n",
            "63\n",
            "[0, 0, 0, 0, 1]\n",
            "64\n",
            "[1, 1, 1, 0, 0]\n",
            "65\n",
            "[8, 8, 9, 7]\n",
            "66\n",
            "[5, 4, 5, 5]\n",
            "67\n",
            "[5, 5, 4, 4, 4]\n",
            "68\n",
            "[5, 5, 5, 4, 5, 5]\n",
            "69\n",
            "[2, 2, 3, 3, 2]\n",
            "70\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from sklearn import metrics\n",
        "import pandas as pd\n",
        "import os\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "top_left_box = [248,150]#200\n",
        "bottom_right_box = [385,400]#400\n",
        "\n",
        "id = 0\n",
        "video_path = '/content/Real_Filter.mp4'\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "cl = [(0,0,0),(0,255,0),(0,0,255)] #black, green, red\n",
        "color_ = cl[2]\n",
        "Arr_count = []\n",
        "Sign_frameOrigin = True\n",
        "\n",
        "frame_width = 640\n",
        "frame_height = 640\n",
        "frame_rate = 30\n",
        "\n",
        "numberCells = 0\n",
        "\n",
        "count_frame = 0\n",
        "\n",
        "# Táº¡o Ä‘á»‘i tÆ°á»£ng VideoWriter Ä‘á»ƒ lÆ°u video\n",
        "video_output_filename = '8_frame.avi'\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "out = cv2.VideoWriter(video_output_filename, fourcc, frame_rate, (frame_width, frame_height))\n",
        "\n",
        "if (cap.isOpened()== False):\n",
        "    print(\"Error opening video file\")\n",
        "while cap.isOpened():\n",
        "    ret, img = cap.read()\n",
        "    if ret: # cÃ³ áº£nh lÃ  show\n",
        "      frame_sub = img[250:900,525:1265]\n",
        "      frame_sub = cv2.resize(frame_sub, (640, 640))\n",
        "      img_sub = frame_sub.copy()#don't draw in here\n",
        "\n",
        "      cv2.putText(frame_sub, f'{numberCells}',(260,180),cv2.FONT_HERSHEY_SIMPLEX,1,(255, 0, 0),2, cv2.LINE_AA)\n",
        "      cv2.putText(frame_sub, f'{id}',(200,180),cv2.FONT_HERSHEY_SIMPLEX,1,(255, 0, 0),2, cv2.LINE_AA)\n",
        "\n",
        "      cv2.rectangle(frame_sub, (top_left_box[0],top_left_box[1]),(bottom_right_box[0],bottom_right_box[1]), color_, 2)\n",
        "      Arr_in4,len_Arrin4 = get_info_Droplets(img_sub)\n",
        "\n",
        "      check = 0\n",
        "\n",
        "      for i in range(0,len_Arrin4):\n",
        "        x1,y1,x2,y2 = Arr_in4[i][0],Arr_in4[i][1],Arr_in4[i][2],Arr_in4[i][3]\n",
        "        # print(Arr_in4[i])\n",
        "        # print(\"And\")\n",
        "        if (y1 > top_left_box[1] and y2 < bottom_right_box[1]):\n",
        "          cv2.rectangle(frame_sub, (x1,y1),(x2,y2), cl[1], 2)\n",
        "          c_x = (x1+x2)/2\n",
        "          c_y = (y1+y2)/2\n",
        "          h_ = y2-y1\n",
        "          x1_new = int(c_x - h_/2)\n",
        "          x2_new = int(c_x + h_/2)\n",
        "          y1_new = int(c_y - h_/2)\n",
        "          y2_new = int(c_y + h_/2)\n",
        "          use_predImg = img_sub[y1_new:y2_new,x1_new:x2_new]\n",
        "          used_pred = pp(use_predImg)\n",
        "          count,check_img = predict(used_pred,model,param=(x2_new-x1_new,y2_new-y1_new))\n",
        "          # print(count)\n",
        "          Arr_count.append(count)\n",
        "          # cv2_imshow(use_predImg)\n",
        "          check = 1\n",
        "\n",
        "      # cv2_imshow(img)\n",
        "      # print(len_Arrin4)\n",
        "\n",
        "      if(check == 0 and Arr_count != []): # trong 1 frame khong co giot nao trong vung lam viec\n",
        "        Arr_count = Arr_count[0:8]\n",
        "        numberCells = vote(Arr_count)\n",
        "        print(Arr_count)\n",
        "        Arr_count = []\n",
        "        id+=1\n",
        "        print(id)\n",
        "      out.write(frame_sub)\n",
        "      if cv2.waitKey(25) & 0xFF == ord('q'):\n",
        "        break\n",
        "    else:\n",
        "        break\n",
        "cap.release()\n",
        "out.release()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}